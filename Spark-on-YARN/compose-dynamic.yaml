#networks:
  # hadoop_net:
  #   driver: bridge


networks:
  data_network:
    driver: bridge
    name: data_network
    external: true 

services:
  mysql:
    image: mysql:5.7
    container_name: mysql
    environment:
      MYSQL_ROOT_PASSWORD: root
      MYSQL_DATABASE: metastore_db
      MYSQL_USER: hiveuser
      MYSQL_PASSWORD: hivepw
    volumes:
      - mysql-data:/var/lib/mysql
    networks:
      - data_network


  client:
    image: client
    container_name: client
    hostname: quochuy-client
    volumes:
     - ./scripts:/home/hadoopquochuy/scripts
     - ./data:/home/hadoopquochuy/data

    networks:
      - data_network
    command: /bin/bash -c "service ssh start; tail -f /dev/null"

  master:
    image: master-official
    container_name: master-huy
    hostname: quochuy-master
    volumes:
      - hdfs_namenode:/home/hadoopquochuy/hadoop/hadoop_data/hdfs/namenode
      - ./scripts:/home/hadoopquochuy/scripts
      - ./data:/home/hadoopquochuy/data

    ports:
      - "9004:9004"
      - "9870:9870"

    networks:
      - data_network
    command: /bin/bash -c "service ssh start; tail -f /dev/null"
# NEW_WORKERS_MARKER
# dynamic workers will be inserted here
  
    
  worker1:
    image: worker
    container_name: worker-huy1
    hostname: quochuy-worker1
    volumes:
      - hdfs_datanode1:/home/hadoopquochuy/hadoop/hadoop_data/hdfs/datanode
    networks:
      - data_network
    command: /bin/bash -c "service ssh start; tail -f /dev/null"

  worker2:
    image: worker
    container_name: worker-huy2
    hostname: quochuy-worker2
    volumes:
      - hdfs_datanode2:/home/hadoopquochuy/hadoop/hadoop_data/hdfs/datanode
    networks:
      - data_network
    command: /bin/bash -c "service ssh start; tail -f /dev/null"


volumes:
  mysql-data:
  hive-metastore:
  hdfs_namenode:
  hdfs_datanode1:
  hdfs_datanode2:
